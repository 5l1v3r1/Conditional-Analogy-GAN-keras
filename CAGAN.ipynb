{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instance_normalization import InstanceNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_axis=-1\n",
    "channel_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_in = 9\n",
    "nc_out = 4\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "use_lsgan = False\n",
    "use_nsgan = False # non-saturating GAN\n",
    "Î» = 10 if use_lsgan else 100\n",
    "\n",
    "# ========== CAGAN config ==========\n",
    "nc_G_inp = 9 # [x_im y_im y_j]\n",
    "nc_G_out = 4 # [alpha, x_i_j(RGB)]\n",
    "nc_D_inp = 6 # Pos: [x_i, y_i]; Neg1: [G_out(x_i), y_i]; Neg2: [x_i, y_j]\n",
    "nc_D_out = 1 \n",
    "gamma_i = 0.1\n",
    "use_instancenorm = True\n",
    "\n",
    "loadSize = 143\n",
    "imageSize = 128\n",
    "batchSize = 16 #1\n",
    "lrD = 2e-4\n",
    "lrG = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "def __conv_init(a):\n",
    "    print(\"conv_init\", a)\n",
    "    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "    k.conv_weight = True    \n",
    "    return k\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic discriminator\n",
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "\n",
    "def instance_norm():\n",
    "    return InstanceNormalization(axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "\n",
    "def BASIC_D(nc_in, ndf, max_layers=3, use_sigmoid=True):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "    if channel_first:\n",
    "        input_a =  Input(shape=(nc_in, None, None))\n",
    "    else:\n",
    "        input_a = Input(shape=(None, None, nc_in))\n",
    "    _ = input_a\n",
    "    _ = conv2d(ndf, kernel_size=4, strides=2, padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=4, strides=2, padding=\"same\", \n",
    "                   use_bias=False, name = 'pyramid.{0}'.format(layer)             \n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(out_feat, kernel_size=4,  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(1, kernel_size=4, name = 'final'.format(out_feat, 1), \n",
    "               activation = \"sigmoid\" if use_sigmoid else None) (_)    \n",
    "    return Model(inputs=[input_a], outputs=_)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unet or Resnet, which one is better for pix2pix model? \n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/117\n",
    "Reply from the author:\n",
    "    UNet gives slightly better results than Resnet in some of the pix2pix applications. \n",
    "    We haven't varied the depth of the UNet model, but it might be worth trying.\n",
    "\"\"\"\n",
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True, use_batchnorm=True):\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    _ = inputs = Input(shape=(s, int(s*.75), nc_in))\n",
    "    x_i = Lambda(lambda x: x[:, :, :, 0:3], name='x_i')(inputs)\n",
    "    y_i = Lambda(lambda x: x[:, :, :, 3:6], name='y_j')(inputs)\n",
    "    xi_and_y_i = concatenate([x_i, y_i], name = 'xi_yi')\n",
    "    xi_yi_sz64 = AveragePooling2D(pool_size=2)(xi_and_y_i)\n",
    "    xi_yi_sz32 = AveragePooling2D(pool_size=4)(xi_and_y_i)\n",
    "    xi_yi_sz16 = AveragePooling2D(pool_size=8)(xi_and_y_i)\n",
    "    xi_yi_sz8 = AveragePooling2D(pool_size=16)(xi_and_y_i)\n",
    "    layer1 = conv2d(64, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer1') (_)\n",
    "    layer1 = LeakyReLU(alpha=0.2)(layer1)\n",
    "    layer1 = concatenate([layer1, xi_yi_sz64]) # ==========\n",
    "    layer2 = conv2d(128, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer2') (layer1)\n",
    "    if use_instancenorm:\n",
    "        layer2 = instance_norm()(layer2, training=1)\n",
    "    else:\n",
    "        layer2 = batchnorm()(layer2, training=1)\n",
    "    layer3 = LeakyReLU(alpha=0.2)(layer2)\n",
    "    layer3 = concatenate([layer3, xi_yi_sz32]) # ==========\n",
    "    layer3 = conv2d(256, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer3') (layer3)\n",
    "    if use_instancenorm:\n",
    "        layer3 = instance_norm()(layer3, training=1)\n",
    "    else:\n",
    "        layer3 = batchnorm()(layer3, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer3)\n",
    "    layer4 = concatenate([layer4, xi_yi_sz16]) # ==========\n",
    "    layer4 = conv2d(512, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer4') (layer4)\n",
    "    if use_instancenorm:\n",
    "        layer4 = instance_norm()(layer4, training=1)\n",
    "    else:\n",
    "        layer4 = batchnorm()(layer4, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer4)\n",
    "    layer4 = concatenate([layer4, xi_yi_sz8]) # ==========\n",
    "    \n",
    "    layer9 = Conv2DTranspose(256, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init, name = 'layer9')(layer4) \n",
    "    layer9 = Cropping2D(((1,1),(1,1)))(layer9)\n",
    "    if use_instancenorm:\n",
    "        layer9 = instance_norm()(layer9, training=1)\n",
    "    else:\n",
    "        layer9 = batchnorm()(layer9, training=1)\n",
    "    layer9 = Concatenate(axis=channel_axis)([layer9, layer3])\n",
    "    layer9 = Activation('relu')(layer9)\n",
    "    layer9 = concatenate([layer9, xi_yi_sz16]) # ==========\n",
    "    layer10 = Conv2DTranspose(128, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init, name = 'layer10')(layer9) \n",
    "    layer10 = Cropping2D(((1,1),(1,1)))(layer10)\n",
    "    if use_instancenorm:\n",
    "        layer10 = instance_norm()(layer10, training=1)\n",
    "    else:\n",
    "        layer10 = batchnorm()(layer10, training=1)\n",
    "    layer10 = Concatenate(axis=channel_axis)([layer10, layer2])\n",
    "    layer10 = Activation('relu')(layer10)\n",
    "    layer10 = concatenate([layer10, xi_yi_sz32]) # ==========\n",
    "    layer11 = Conv2DTranspose(64, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init, name = 'layer11')(layer10) \n",
    "    layer11 = Cropping2D(((1,1),(1,1)))(layer11)\n",
    "    if use_instancenorm:\n",
    "        layer11 = instance_norm()(layer11, training=1)\n",
    "    else:\n",
    "        layer11 = batchnorm()(layer11, training=1)\n",
    "    layer11 = Activation('relu')(layer11)\n",
    "        \n",
    "    layer12 = concatenate([layer11, xi_yi_sz64]) # ==========\n",
    "    layer12 = Activation('relu')(layer12)\n",
    "    layer12 = Conv2DTranspose(32, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init, name = 'layer12')(layer12) \n",
    "    layer12 = Cropping2D(((1,1),(1,1)))(layer12)\n",
    "    if use_instancenorm:\n",
    "        layer12 = instance_norm()(layer12, training=1)\n",
    "    else:\n",
    "        layer12 = batchnorm()(layer12, training=1)\n",
    "    \n",
    "    layer12 = conv2d(4, kernel_size=4, strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'out128') (layer12)\n",
    "    \n",
    "    alpha = Lambda(lambda x: x[:, :, :, 0:1], name='alpha')(layer12)\n",
    "    x_i_j = Lambda(lambda x: x[:, :, :, 1:], name='x_i_j')(layer12)\n",
    "    alpha = Activation(\"sigmoid\", name='alpha_sigmoid')(alpha)\n",
    "    x_i_j = Activation(\"tanh\", name='x_i_j_tanh')(x_i_j)\n",
    "    out = concatenate([alpha, x_i_j], name = 'out128_concat')\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=[out])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netGA = UNET_G(imageSize, nc_G_inp, nc_G_out, ngf)\n",
    "#netGA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netDA = BASIC_D(nc_D_inp, ndf, use_sigmoid = not use_lsgan)\n",
    "#netDA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cycle_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_variables(netG1):\n",
    "    \"\"\"\n",
    "    Intermidiate params:\n",
    "        x_i: human w/ cloth i, shape=(128,96,3)\n",
    "        y_i: stand alone cloth i, shape=(128,96,3)\n",
    "        y_j: stand alone cloth j, shape=(128,96,3)\n",
    "        alpha: mask for x_i_j, shape=(128,96,1)\n",
    "        x_i_j: generated fake human swapping cloth i to j, shape=(128,96,3)\n",
    "    \n",
    "    Out:\n",
    "        real_input: concat[x_i, y_i, y_j], shape=(128,96,9)\n",
    "        fake_output: masked_x_i_j = alpha*x_i_j + (1-alpha)*x_i, shape=(128,96,3)\n",
    "        rec_input: output of the second generator (generating image similar to x_i), shape=(128,96,3)\n",
    "        fn_generate: a path from input to G_out and cyclic G_out\n",
    "    \"\"\"\n",
    "    real_input = netG1.inputs[0]\n",
    "    fake_output = netG1.outputs[0]\n",
    "    # Legacy: how to split channels\n",
    "    # https://github.com/fchollet/keras/issues/5474\n",
    "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real_input)\n",
    "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real_input)\n",
    "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real_input)\n",
    "    alpha = Lambda(lambda x: x[:,:,:, 0:1])(fake_output)\n",
    "    x_i_j = Lambda(lambda x: x[:,:,:, 1:])(fake_output)\n",
    "    \n",
    "    fake_output = alpha*x_i_j + (1-alpha)*x_i \n",
    "    concat_input_G2 = concatenate([fake_output, y_j, y_i], axis=-1) # swap y_i and y_j\n",
    "    rec_input = netG1([concat_input_G2])\n",
    "    rec_alpha = Lambda(lambda x: x[:,:,:, 0:1])(rec_input)\n",
    "    rec_x_i_j = Lambda(lambda x: x[:,:,:, 1:])(rec_input)\n",
    "    rec_input = rec_alpha*rec_x_i_j + (1-rec_alpha)*fake_output\n",
    "    fn_generate = K.function([real_input], [fake_output, rec_input])\n",
    "    return real_input, fake_output, rec_input, fn_generate, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A, fake_B, rec_A, cycleA_generate, alpha_A = cycle_variables(netGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lsgan:\n",
    "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "else:\n",
    "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(netD, real, fake, rec):\n",
    "    #x_i, y_i, y_j = tf.split(real, [3, 3, 3], 3)    \n",
    "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real)\n",
    "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real)\n",
    "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real)\n",
    "    x_i_j = fake  \n",
    "    \n",
    "    output_real = netD(concatenate([x_i, y_i])) # positive sample\n",
    "    output_fake = netD(concatenate([x_i_j, y_j])) # negative sample\n",
    "    output_fake2 = netD(concatenate([x_i, y_j])) # negative sample 2\n",
    "    \n",
    "    loss_D_real = loss_fn(output_real, K.ones_like(output_real))    \n",
    "    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))\n",
    "    loss_D_fake2 = loss_fn(output_fake2, K.zeros_like(output_fake2)) # New loss term for discriminator    \n",
    "    if not use_nsgan:\n",
    "        loss_G = loss_fn(output_fake, K.ones_like(output_fake))\n",
    "    else:\n",
    "        loss_G = K.mean(K.log(output_fake))\n",
    "    \n",
    "    loss_D = loss_D_real+(loss_D_fake+loss_D_fake2)\n",
    "    loss_cyc = K.mean(K.abs(rec-x_i)) # cycle loss\n",
    "    return loss_D, loss_G, loss_cyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_DA, loss_GA, loss_cycA = D_loss(netDA, real_A, fake_B, rec_A)\n",
    "loss_cyc = loss_cycA\n",
    "loss_id = K.mean(K.abs(alpha_A)) # loss of alpha\n",
    "\n",
    "loss_G = loss_GA + 1*(1*loss_cyc + gamma_i*loss_id)\n",
    "loss_D = loss_DA*2\n",
    "\n",
    "weightsD = netDA.trainable_weights\n",
    "weightsG = netGA.trainable_weights\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(weightsD,[],loss_D)\n",
    "netD_train = K.function([real_A],[loss_DA/2], training_updates)\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(weightsG,[], loss_G)\n",
    "netG_train = K.function([real_A], [loss_GA, loss_cyc], training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Image\n",
    "\n",
    "Filenames:\n",
    "\n",
    "    \"./imgs/1/fileID_1.jpg\" for human images.\n",
    "    \"./imgs/5/fileID_5.jpg\" for article images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRGB = True\n",
    "apply_da = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_pattern):\n",
    "    return glob.glob(file_pattern)\n",
    "\n",
    "def crop_img(img, large_size, small_size):\n",
    "    # only apply DA to human images\n",
    "    img_width = small_size[0]\n",
    "    img_height = small_size[1]\n",
    "    diff_size = (large_size[0]-small_size[0], large_size[1]-small_size[1])\n",
    "    \n",
    "    x_range = [i for i in range(diff_size[0])]\n",
    "    y_range = [j for j in range(diff_size[1])]\n",
    "    x0 = np.random.choice(x_range)\n",
    "    y0 = np.random.choice(y_range)\n",
    "    \n",
    "    img = np.array(img)\n",
    "    \n",
    "    img = img[y0: y0+img_height, x0: x0+img_width, :]\n",
    "    \n",
    "    return img\n",
    "\n",
    "def read_image(fn):\n",
    "    input_size = (111,148)\n",
    "    cropped_size = (96,128)\n",
    "    \n",
    "    if isRGB:\n",
    "    # Load human picture\n",
    "        im = Image.open(fn).convert('RGB')\n",
    "        im = im.resize( input_size, Image.BILINEAR )    \n",
    "    else:\n",
    "        im = cv2.imread(fn)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        im = cv2.resize(im, input_size, interpolation=cv2.INTER_CUBIC)\n",
    "    if apply_da is True:\n",
    "        im = crop_img(im, input_size, cropped_size)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_x_i = arr\n",
    "    if channel_first:        \n",
    "        img_x_i = np.moveaxis(img_x_i, 2, 0)\n",
    "        \n",
    "    # Load article picture y_i\n",
    "    fn_y_i = fn[:-5] + \"5.jpg\"\n",
    "    fn_y_i = fn_y_i[:fn_y_i.rfind(\"/\")-1] + \"5/\" + fn_y_i.split(\"/\")[-1]\n",
    "    if isRGB:\n",
    "        im = Image.open(fn_y_i).convert('RGB')\n",
    "        im = im.resize(cropped_size, Image.BILINEAR )    \n",
    "    else:\n",
    "        im = cv2.imread(fn_y_i)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_y_i = arr\n",
    "    if channel_first:        \n",
    "        img_y_i = np.moveaxis(img_y_i, 2, 0)\n",
    "    \n",
    "    # Load article picture y_j randomly\n",
    "    fn_y_j = np.random.choice(filenames_5)\n",
    "    while (fn_y_j == fn_y_i):\n",
    "        fn_y_j = np.random.choice(filenames_5)\n",
    "    if isRGB:\n",
    "        im = Image.open(fn_y_j).convert('RGB')\n",
    "        im = im.resize( cropped_size, Image.BILINEAR )\n",
    "    else:\n",
    "        im = cv2.imread(fn_y_j)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_y_j = arr\n",
    "    if randint(0,1): \n",
    "        img_y_j=img_y_j[:,::-1]\n",
    "    if channel_first:        \n",
    "        img_y_j = np.moveaxis(img_y_j, 2, 0)        \n",
    "    \n",
    "    if randint(0,1): # prevent disalign of the graphic on t-shirts and human when fplipping\n",
    "        img_x_i=img_x_i[:,::-1]\n",
    "        img_y_i=img_y_i[:,::-1]\n",
    "    \n",
    "    img = np.concatenate([img_x_i, img_y_i, img_y_j], axis=-1)    \n",
    "    assert img.shape[-1] == 9\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imgs\"\n",
    "train_A = load_data('./{}/1/*.jpg'.format(data))\n",
    "\n",
    "filenames_1 = load_data('./{}/1/*.jpg'.format(data))\n",
    "filenames_5 = load_data('./{}/5/*.jpg'.format(data))\n",
    "\n",
    "assert len(train_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(data, batchsize):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB(dataA, batchsize):\n",
    "    batchA=minibatch(dataA, batchsize)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        tmpsize = yield ep1, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    #print (int_X.shape)\n",
    "    if channel_first:\n",
    "        int_X = np.moveaxis(int_X.reshape(-1,3,128,96), 1, 3)\n",
    "    else:\n",
    "        if X.shape[-1] == 9:\n",
    "            img_x_i = int_X[:,:,:,:3]\n",
    "            img_y_i = int_X[:,:,:,3:6]\n",
    "            img_y_j = int_X[:,:,:,6:9]\n",
    "            int_X = np.concatenate([img_x_i, img_y_i, img_y_j], axis=1)\n",
    "        else:\n",
    "            int_X = int_X.reshape(-1,128,96, 3)\n",
    "    int_X = int_X.reshape(rows, -1, 128, 96,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
    "    if not isRGB:\n",
    "        int_X = cv2.cvtColor(int_X, cv2.COLOR_LAB2RGB)\n",
    "    display(Image.fromarray(int_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showG(A):\n",
    "    def G(fn_generate, X):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycleA_generate, A)\n",
    "    arr = np.concatenate([A[:,:,:,:3], A[:,:,:,3:6], A[:,:,:,6:9], rA[0], rA[1]])\n",
    "    showX(arr,5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Show results every 50 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "niter = 150\n",
    "gen_iterations = 0\n",
    "epoch = 0\n",
    "errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0\n",
    "\n",
    "display_iters = 50\n",
    "train_batch = minibatchAB(train_A, batchSize)\n",
    "\n",
    "#while epoch < niter: \n",
    "while gen_iterations < 5000:\n",
    "    epoch, A = next(train_batch)   \n",
    "    errDA  = netD_train([A])\n",
    "    errDA_sum +=errDA[0]\n",
    "\n",
    "    # epoch, trainA, trainB = next(train_batch)\n",
    "    errGA, errCyc = netG_train([A])\n",
    "    errGA_sum += errGA\n",
    "    errCyc_sum += errCyc\n",
    "    gen_iterations+=1\n",
    "    if gen_iterations%display_iters==0:\n",
    "        if gen_iterations%(10*display_iters)==0: # clear_output every 500 iters\n",
    "            clear_output()\n",
    "        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_cyc: %f'\n",
    "        % (epoch, niter, gen_iterations, errDA_sum/display_iters,\n",
    "           errGA_sum/display_iters, errCyc_sum/display_iters), time.time()-t0)        \n",
    "        _, A = train_batch.send(4)\n",
    "        showG(A)        \n",
    "        errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "Show 8 results on the same target article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_demo(data, batchsize, fn_y_i=None):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None\n",
    "    shuffle(data)\n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1    \n",
    "        rtn = [read_image(data[j], fn_y_i) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB_demo(dataA, batchsize, fn_y_i=None):\n",
    "    batchA=minibatch_demo(dataA, batchsize, fn_y_i=fn_y_i)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        tmpsize = yield ep1, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_fn = len(filenames_5)\n",
    "assert len_fn > 0\n",
    "idx = np.random.randint(len_fn)\n",
    "fn = filenames_5[idx]\n",
    "\n",
    "demo_batch = minibatchAB_demo(train_A, batchSize, fn)\n",
    "epoch, A = next(demo_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, A = demo_batch.send(8)\n",
    "showG(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
