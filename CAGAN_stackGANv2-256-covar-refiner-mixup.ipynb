{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.distributions import Beta\n",
    "from random import shuffle\n",
    "from instance_normalization import InstanceNormalization\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_axis=-1\n",
    "channel_first = False\n",
    "\n",
    "#nc_in = 9 # number of input channel\n",
    "#nc_out = 4 # number of output channel\n",
    "\n",
    "# ========== Model config ==========\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "use_lsgan = False\n",
    "Î» = 10 if use_lsgan else 100\n",
    "nc_G_inp = 9 \n",
    "nc_G_out = 4 \n",
    "nc_D_inp = 6 \n",
    "nc_D_out = 1 \n",
    "gamma_i = 0.1\n",
    "use_instancenorm = True # False: batchnorm\n",
    "use_mixup = True\n",
    "linear_upsampling = False\n",
    "\n",
    "#========== Training config ==========\n",
    "mixup_alpha = 0.1\n",
    "imageSize = 256\n",
    "batchSize = 8\n",
    "lrD = 2e-4\n",
    "lrG = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "def __conv_init(a):\n",
    "    print(\"conv_init\", a)\n",
    "    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "    k.conv_weight = True    \n",
    "    return k\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks/blob/master/models.py\n",
    "def upscale_block(ip, nf_out):\n",
    "    '''\n",
    "    As per suggestion from http://distill.pub/2016/deconv-checkerboard/, I am swapping out\n",
    "    SubPixelConvolution to simple Nearest Neighbour Upsampling\n",
    "    '''\n",
    "    init = ip\n",
    "    \n",
    "    if not nf_out == 3:\n",
    "        x = Conv2D(nf_out, kernel_size=(4,3), strides=1, activation=\"linear\", padding='same', \n",
    "                   kernel_initializer=conv_init, use_bias=False)(init)\n",
    "        x = LeakyReLU(alpha=0.25)(x)\n",
    "    else:\n",
    "        x = init\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(nf_out, kernel_size=(4,3), strides=1, activation=\"linear\", padding='same', \n",
    "               kernel_initializer=conv_init, use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "\n",
    "def instance_norm():\n",
    "    return InstanceNormalization(axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "\n",
    "# Basic discriminator\n",
    "def BASIC_D(nc_in, ndf, max_layers=3, use_sigmoid=True):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "    if channel_first:\n",
    "        input_a =  Input(shape=(nc_in, None, None))\n",
    "    else:\n",
    "        input_a = Input(shape=(None, None, nc_in))\n",
    "    _ = input_a\n",
    "    _ = GaussianNoise(0.05)(_) # ====================\n",
    "    _ = conv2d(ndf, kernel_size=4, strides=2, padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=4, strides=2, padding=\"same\", \n",
    "                   use_bias=False, name = 'pyramid.{0}'.format(layer)             \n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(out_feat, kernel_size=4,  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(1, kernel_size=4, name = 'final'.format(out_feat, 1), \n",
    "               activation = \"sigmoid\" if use_sigmoid else None) (_)    \n",
    "    return Model(inputs=[input_a], outputs=_)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unet or Resnet, which one is better for pix2pix model? \n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/117\n",
    "Reply from the author:\n",
    "    UNet gives slightly better results than Resnet in some of the pix2pix applications. \n",
    "    We haven't varied the depth of the UNet model, but it might be worth trying.\n",
    "\"\"\"\n",
    "\n",
    "def UNET_G_dilated256(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True, use_batchnorm=True):\n",
    "    \n",
    "    # res_block from cycleGAN-keras (PiscesDream)\n",
    "    def res_block(inp, ch):\n",
    "        x = inp\n",
    "        #x = padding()(x) # reflectPadding2D ?\n",
    "        x = conv2d(ch, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\") (x)\n",
    "        if use_instancenorm:\n",
    "            x = instance_norm()(x, training=1)\n",
    "        else:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        x = Activation('relu')(x)\n",
    "        #x = padding()(x) \n",
    "        x = conv2d(ch, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\") (x)\n",
    "        if use_instancenorm:\n",
    "            x = instance_norm()(x, training=1)\n",
    "        else:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        \n",
    "        x = se_block(x)\n",
    "        x = add([x, inp])\n",
    "        return x\n",
    "    \n",
    "    def refiner_network(inp, output_channel, res_block_channel=32):\n",
    "        x = inp\n",
    "        x = conv2d(res_block_channel, kernel_size=1, strides=1, use_bias=(not (use_batchnorm and s>2)))(x) \n",
    "        for i in range(2):\n",
    "            x = res_block(x, res_block_channel)\n",
    "        x = conv2d(output_channel, kernel_size=1, strides=1, use_bias=(not (use_batchnorm and s>2)))(x) \n",
    "        x = add([x, inp])\n",
    "        return x\n",
    "    \n",
    "    def se_block(input_tensor, compress_rate = 8):\n",
    "        num_channels = int(input_tensor.shape[-1]) # Tensorflow backend\n",
    "        bottle_neck = int(num_channels//compress_rate)\n",
    "\n",
    "        se_branch = GlobalAveragePooling2D()(input_tensor)\n",
    "        se_branch = Dense(bottle_neck, activation='relu')(se_branch)\n",
    "        se_branch = Dense(num_channels, activation='sigmoid')(se_branch)\n",
    "\n",
    "        x = input_tensor \n",
    "        out = multiply([x, se_branch])\n",
    "\n",
    "        return out\n",
    "            \n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    _ = inputs = Input(shape=(s, int(s*.75), nc_in))\n",
    "    x_i = Lambda(lambda x: x[:, :, :, 0:3], name='x_i')(inputs)\n",
    "    y_j = Lambda(lambda x: x[:, :, :, 6:], name='y_j')(inputs)\n",
    "    xi_and_yj = concatenate([x_i, y_j], name = 'xi_yj')\n",
    "    xi_yj_sz128 = AveragePooling2D(pool_size=2)(xi_and_yj) # Using MaxPooling2D increase artifact in output images\n",
    "    xi_yj_sz64 = AveragePooling2D(pool_size=4)(xi_and_yj)\n",
    "    \n",
    "    layer1 = conv2d(64, kernel_size=(4,3), strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer1') (_)\n",
    "    layer1 = LeakyReLU(alpha=0.2)(layer1)\n",
    "    layer1 = concatenate([layer1, xi_yj_sz128]) \n",
    "    layer2 = conv2d(128, kernel_size=(4,3), strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer2') (layer1)\n",
    "    if use_instancenorm:\n",
    "        layer2 = instance_norm()(layer2, training=1)\n",
    "    else:\n",
    "        layer2 = batchnorm()(layer2, training=1)\n",
    "    layer3 = LeakyReLU(alpha=0.2)(layer2)\n",
    "    layer3 = concatenate([layer3, xi_yj_sz64])\n",
    "    layer3 = conv2d(256, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'layer3') (layer3)\n",
    "    if use_instancenorm:\n",
    "        layer3 = instance_norm()(layer3, training=1)\n",
    "    else:\n",
    "        layer3 = batchnorm()(layer3, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer3)\n",
    "    layer4 = concatenate([layer4, xi_yj_sz64]) \n",
    "    layer4 = conv2d(256, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)), dilation_rate=(2, 2),\n",
    "                   padding=\"same\", name = 'layer4') (layer4)\n",
    "    if use_instancenorm:\n",
    "        layer4 = instance_norm()(layer4, training=1)\n",
    "    else:\n",
    "        layer4 = batchnorm()(layer4, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer4)\n",
    "    layer4 = concatenate([layer4, xi_yj_sz64]) \n",
    "    \n",
    "    layer5 = LeakyReLU(alpha=0.2)(layer4)\n",
    "    layer5 = conv2d(256, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)), dilation_rate=(2, 2),\n",
    "                   padding=\"same\", name = 'layer5') (layer5)\n",
    "    if use_instancenorm:\n",
    "        layer5 = instance_norm()(layer5, training=1)\n",
    "    else:\n",
    "        layer5 = batchnorm()(layer5, training=1)    \n",
    "    layer5 = LeakyReLU(alpha=0.2)(layer5)\n",
    "    layer5 = concatenate([layer5, xi_yj_sz64]) \n",
    "    \n",
    "    layer8 = Conv2D(256, kernel_size=(4,3), strides=1, use_bias=not use_batchnorm, dilation_rate=(2, 2), padding=\"same\",\n",
    "                    kernel_initializer = conv_init, name = 'layer8')(layer5) \n",
    "    if use_instancenorm:\n",
    "        layer8 = instance_norm()(layer8, training=1)\n",
    "    else:\n",
    "        layer8 = batchnorm()(layer8, training=1)\n",
    "    layer8 = Activation('relu')(layer8)  \n",
    "    layer8 = Concatenate(axis=channel_axis)([layer8, layer4])\n",
    "        \n",
    "    layer9 = Conv2D(256, kernel_size=(4,3), strides=1, use_bias=not use_batchnorm, dilation_rate=(2, 2), padding=\"same\",\n",
    "                            kernel_initializer = conv_init, name = 'layer9')(layer8) \n",
    "    if use_instancenorm:\n",
    "        layer9 = instance_norm()(layer9, training=1)\n",
    "    else:\n",
    "        layer9 = batchnorm()(layer9, training=1)\n",
    "    layer9 = Concatenate(axis=channel_axis)([layer9, layer3])\n",
    "    layer9 = Activation('relu')(layer9)\n",
    "    layer9 = concatenate([layer9, xi_yj_sz64]) \n",
    "    layer10 = Conv2D(128, kernel_size=(4,3), strides=1, use_bias=not use_batchnorm, padding=\"same\",\n",
    "                            kernel_initializer = conv_init, name = 'layer10')(layer9) \n",
    "    if use_instancenorm:\n",
    "        layer10 = instance_norm()(layer10, training=1)\n",
    "    else:\n",
    "        layer10 = batchnorm()(layer10, training=1)\n",
    "    layer10 = Concatenate(axis=channel_axis)([layer10, layer2])\n",
    "    layer10 = Activation('relu')(layer10)\n",
    "    \n",
    "    # Output branch 0\n",
    "    out64 = layer10\n",
    "    out64 = conv2d(4, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'out64') (out64)\n",
    "    out64_alpha = Lambda(lambda x: x[:, :, :, 0:1], name='alpha64')(out64)\n",
    "    out64_x_i_j = Lambda(lambda x: x[:, :, :, 1:], name='x_i_j64')(out64)\n",
    "    out64_alpha = Activation(\"sigmoid\", name='out64_alpha_sigmoid')(out64_alpha)\n",
    "    out64_x_i_j = Activation(\"tanh\", name='out64_x_i_j_tanh')(out64_x_i_j)\n",
    "    out64 = concatenate([out64_alpha, out64_x_i_j], name = 'out64_concat')    \n",
    "    \n",
    "    layer10 = concatenate([layer10, xi_yj_sz64])\n",
    "    layer11 = refiner_network(layer10, 262, res_block_channel=64)\n",
    "    layer11 = Activation('relu')(layer11)\n",
    "    if linear_upsampling:\n",
    "        layer11 = upscale_block(layer11, 64)\n",
    "    else:\n",
    "        layer11 = Conv2DTranspose(64, kernel_size=(4,3), strides=2, use_bias=not use_batchnorm,\n",
    "                                kernel_initializer = conv_init, name = 'layer11')(layer11) \n",
    "        layer11 = Cropping2D(((1,1),(1,0)))(layer11)\n",
    "    \n",
    "    if use_instancenorm:\n",
    "        layer11 = instance_norm()(layer11, training=1)\n",
    "    else:\n",
    "        layer11 = batchnorm()(layer11, training=1)\n",
    "    layer11 = Activation('relu')(layer11)\n",
    "    \n",
    "    # Output branch 1\n",
    "    out128 = layer11\n",
    "    out128 = conv2d(4, kernel_size=(4,3), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'out128') (out128)\n",
    "    out128_alpha = Lambda(lambda x: x[:, :, :, 0:1], name='alpha128')(out128)\n",
    "    out128_x_i_j = Lambda(lambda x: x[:, :, :, 1:], name='x_i_j128')(out128)\n",
    "    out128_alpha = Activation(\"sigmoid\", name='out128_alpha_sigmoid')(out128_alpha)\n",
    "    out128_x_i_j = Activation(\"tanh\", name='out128_x_i_j_tanh')(out128_x_i_j)\n",
    "    out128 = concatenate([out128_alpha, out128_x_i_j], name = 'out128_concat')\n",
    "    \n",
    "    layer12 = concatenate([layer11, xi_yj_sz128])\n",
    "    layer12 = refiner_network(layer12, 70)\n",
    "    layer12 = Activation('relu')(layer12)\n",
    "    if linear_upsampling:\n",
    "        layer12 = upscale_block(layer12, 32)\n",
    "    else:\n",
    "        layer12 = Conv2DTranspose(32, kernel_size=(4,3), strides=2, use_bias=not use_batchnorm,\n",
    "                                kernel_initializer = conv_init, name = 'layer12')(layer12) \n",
    "        layer12 = Cropping2D(((1,1),(1,0)))(layer12)\n",
    "    \n",
    "    if use_instancenorm:\n",
    "        layer12 = instance_norm()(layer12, training=1)\n",
    "    else:\n",
    "        layer12 = batchnorm()(layer12, training=1)\n",
    "    \n",
    "    # Output branch 2\n",
    "    layer12 = conv2d(4, kernel_size=(8,6), strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'out256') (layer12)    \n",
    "    alpha = Lambda(lambda x: x[:, :, :, 0:1], name='alpha')(layer12)\n",
    "    x_i_j = Lambda(lambda x: x[:, :, :, 1:], name='x_i_j')(layer12)\n",
    "    alpha = Activation(\"sigmoid\", name='alpha_sigmoid')(alpha)\n",
    "    x_i_j = Activation(\"tanh\", name='x_i_j_tanh')(x_i_j)\n",
    "    out = concatenate([alpha, x_i_j], name = 'out256_concat')\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=[out64, out128, out]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netGA = UNET_G_dilated256(imageSize, nc_G_inp, nc_G_out, ngf)\n",
    "netGA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD0 = BASIC_D(nc_D_inp, ndf, use_sigmoid = not use_lsgan)\n",
    "netD1 = BASIC_D(nc_D_inp, ndf, use_sigmoid = not use_lsgan)\n",
    "netD2 = BASIC_D(nc_D_inp, ndf, use_sigmoid = not use_lsgan)\n",
    "netD2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_xij(input_tensor):\n",
    "    alpha = Lambda(lambda x: x[:,:,:, 0:1])(input_tensor)\n",
    "    x_i_j = Lambda(lambda x: x[:,:,:, 1:])(input_tensor)    \n",
    "    return alpha, x_i_j\n",
    "\n",
    "def get_rec_input(netG, input_tensor256, input_tensor, y_j, y_i, out_idx):\n",
    "    concat_input_G2 = concatenate([input_tensor256, y_j, y_i], axis=-1) # swap y_i and y_j\n",
    "    rec_input = netG([concat_input_G2])[out_idx]\n",
    "    rec_alpha, rec_x_i_j = get_alpha_xij(rec_input)\n",
    "    rec_input = rec_alpha*rec_x_i_j + (1-rec_alpha)*input_tensor    \n",
    "    return rec_input\n",
    "\n",
    "def cycle_variables(netG1):\n",
    "    \"\"\"\n",
    "    Intermidiate params:\n",
    "        x_i: human w/ cloth i, shape=(256,192,3)\n",
    "        y_i: stand alone cloth i, shape=(256,192,3)\n",
    "        y_j: stand alone cloth j, shape=(256,192,3)\n",
    "        alpha: mask for x_i_j, shape=(256,192,1)\n",
    "        x_i_j: generated fake human swapping cloth i to j, shape=(256,192,3)\n",
    "    \n",
    "    Out:\n",
    "        real_input: concat[x_i, y_i, y_j], shape=(256,192,9)\n",
    "        fake_output: masked_x_i_j = alpha*x_i_j + (1-alpha)*x_i, shape=(256,192,3)\n",
    "        rec_input: output of cyclic loop, shape=(256,192,3)\n",
    "        idt_input: output of cyclic loop (identity input), shape=(256,192,3)\n",
    "        fn_generate: a path from input to first G_out(masked) and second G_out(masked)\n",
    "    \"\"\"\n",
    "    real_input = netG1.inputs[0]\n",
    "    fake_output0 = netG1.outputs[0] # shape=(64,48,4)\n",
    "    fake_output1 = netG1.outputs[1] # shape=(128,96,4)\n",
    "    fake_output2 = netG1.outputs[2] # shape=(256,192,4)\n",
    "    \n",
    "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real_input)\n",
    "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real_input)\n",
    "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real_input)\n",
    "    x_i_size64 = tf.image.resize_images(x_i, [imageSize//4, int(imageSize*0.75)//4])\n",
    "    x_i_size128 = tf.image.resize_images(x_i, [imageSize//2, int(imageSize*0.75)//2])\n",
    "    \n",
    "    alpha0, x_i_j0 = get_alpha_xij(fake_output0)\n",
    "    alpha1, x_i_j1 = get_alpha_xij(fake_output1)  \n",
    "    alpha2, x_i_j2 = get_alpha_xij(fake_output2) \n",
    "    fake_output0 = alpha0*x_i_j0 + (1-alpha0)*x_i_size64 \n",
    "    fake_output0_resize256 = tf.image.resize_images(fake_output0, [imageSize, int(imageSize*0.75)])\n",
    "    fake_output1 = alpha1*x_i_j1 + (1-alpha1)*x_i_size128 \n",
    "    fake_output1_resize256 = tf.image.resize_images(fake_output1, [imageSize, int(imageSize*0.75)])\n",
    "    fake_output2 = alpha2*x_i_j2 + (1-alpha2)*x_i \n",
    "    \n",
    "    rec_input_size64 = get_rec_input(netG1, fake_output0_resize256, x_i_j0, y_j, y_i, 0) # Pass x_i_j0 instead of fake_output0 for masking\n",
    "    rec_input_size128 = get_rec_input(netG1, fake_output1_resize256, fake_output1, y_j, y_i, 1)\n",
    "    rec_input = get_rec_input(netG1, fake_output2, fake_output2, y_j, y_i, 2)\n",
    "    \n",
    "    idt_input = get_rec_input(netG1, x_i, x_i, y_i, y_i, 2)\n",
    "    \n",
    "    fn_generate0 = K.function([real_input], [fake_output0, rec_input_size64])\n",
    "    fn_generate1 = K.function([real_input], [fake_output1, rec_input_size128])\n",
    "    fn_generate2 = K.function([real_input], [fake_output2, rec_input])\n",
    "    \n",
    "    fake_output_list = [fake_output0, fake_output1, fake_output2]\n",
    "    rec_input_list = [rec_input_size64, rec_input_size128, rec_input]\n",
    "    fn_generate_list = [fn_generate0, fn_generate1, fn_generate2]\n",
    "    alpha_list = [alpha0, alpha1, alpha2]\n",
    "    return real_input, fake_output_list, rec_input_list, fn_generate_list, alpha_list, idt_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naming rules for variables:\n",
    "    _0: tensors from output branch 0\n",
    "    _1: tensors from output branch 1\n",
    "    _2: tensors from output branch 2\n",
    "\"\"\"\n",
    "\n",
    "real, fake_output_list, rec_input_list, fn_generate_list, alpha_list, idt = cycle_variables(netGA)\n",
    "\n",
    "fake_0, fake_1, fake_2 = fake_output_list\n",
    "rec_0, rec_1, rec_2 = rec_input_list\n",
    "cycle0_generate, cycle1_generate, cycle_generate = fn_generate_list\n",
    "alpha_0, alpha_1, alpha_2 = alpha_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lsgan:\n",
    "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "else:\n",
    "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(netD, real, fake, rec, alpha=None, idt=None, is_cyclic=False):\n",
    "    #x_i, y_i, y_j = tf.split(real, [3, 3, 3], 3)    \n",
    "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real)\n",
    "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real)\n",
    "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real)\n",
    "    x_i_j = fake  \n",
    "    \n",
    "    dist = Beta(mixup_alpha, mixup_alpha)\n",
    "    lam = dist.sample()\n",
    "    \n",
    "    if use_mixup:\n",
    "        mixup_x = lam*x_i + (1-lam)*x_i_j\n",
    "        mixup_y = lam*y_i + (1-lam)*y_j\n",
    "        output_real = netD(concatenate([mixup_x, mixup_y])) # positive sample + negative sample\n",
    "        output_fake = netD(concatenate([x_i_j, y_j])) # negative sample (dummy)\n",
    "        output_fake2 = netD(concatenate([x_i, y_j])) # negative sample 2 \n",
    "    else:\n",
    "        output_real = netD(concatenate([x_i, y_i])) # positive sample\n",
    "        output_fake = netD(concatenate([x_i_j, y_j])) # negative sample\n",
    "        output_fake2 = netD(concatenate([x_i, y_j])) # negative sample 2\n",
    "        \n",
    "    if not alpha is None:\n",
    "        alpha_resized = tf.image.resize_images(alpha, [int(output_real.shape[1]), int(output_real.shape[2])])   \n",
    "    else:\n",
    "        alpha_resized = 1\n",
    "    \n",
    "    loss_D_real = loss_fn(output_real, lam*K.ones_like(output_real)) \n",
    "    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))\n",
    "    #loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake) + (1-alpha_resized)*K.ones_like(output_fake))\n",
    "    loss_D_fake2 = loss_fn(output_fake2, K.zeros_like(output_fake2))   \n",
    "    loss_G = loss_fn(output_fake, K.ones_like(output_fake))   \n",
    "    \n",
    "    if use_mixup:\n",
    "        loss_D = loss_D_real+ loss_D_fake2\n",
    "    else:\n",
    "        loss_D = loss_D_real+ (loss_D_fake+loss_D_fake2)\n",
    "    \n",
    "    # cyclic consistency loss\n",
    "    if is_cyclic:\n",
    "        loss_cyc = K.mean(K.abs(rec-x_i))\n",
    "    else:\n",
    "        loss_cyc = 0\n",
    "    \n",
    "    # identity loss\n",
    "    if not idt is None:\n",
    "        loss_cyc += K.mean(K.abs(idt-x_i))\n",
    "        \n",
    "    return loss_D, loss_G, loss_cyc\n",
    "\n",
    "def resize_real(x, sz=[128, 96]):   \n",
    "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(x)\n",
    "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(x)\n",
    "    y_j = Lambda(lambda x: x[:,:,:, 6:])(x)\n",
    "    \n",
    "    x_i = tf.image.resize_images(x_i, sz)\n",
    "    y_i = tf.image.resize_images(y_i, sz)\n",
    "    y_j = tf.image.resize_images(y_j, sz)\n",
    "    \n",
    "    out = concatenate([x_i,y_i, y_j])\n",
    "    return out\n",
    "\n",
    "def compute_covar(input_tensor, mean, sz = (64,48)):\n",
    "    m = K.stack([mean]*sz[0], axis=1)\n",
    "    m = K.stack([m]*sz[1], axis=2)\n",
    "    var_reshape = K.reshape((input_tensor - m), (-1,3))\n",
    "    covar = K.dot(K.transpose(var_reshape), var_reshape)\n",
    "    N = sz[0] * sz[1]\n",
    "    return covar/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_size64 = resize_real(real, sz=[imageSize//4, int(imageSize*0.75)//4])\n",
    "real_size128 = resize_real(real, sz=[imageSize//2, int(imageSize*0.75)//2])\n",
    "loss_D0, loss_G0, loss_cyc0 = D_loss(netD0, real_size64, fake_0, rec_0, is_cyclic=True)\n",
    "loss_D1, loss_G1, loss_cyc1 = D_loss(netD1, real_size128, fake_1, rec_1, is_cyclic=True)\n",
    "loss_D2, loss_G2, loss_cyc2 = D_loss(netD2, real, fake_2, rec_2, idt, is_cyclic=True)\n",
    "loss_cyc = loss_cyc0 + loss_cyc1 + loss_cyc2\n",
    "\n",
    "# loss of alpha mask\n",
    "loss_id = K.mean(K.abs(alpha_0)) + K.mean(K.abs(alpha_1)) + K.mean(K.abs(alpha_2)) \n",
    "\n",
    "# loss - color consistency regularization (StackGan++ Sec. 5.3)\n",
    "mean_64 = K.mean(fake_0, axis=[1,2])\n",
    "covar_64 = compute_covar(fake_0, mean_64, sz=(imageSize//4, int(imageSize*0.75)//4))\n",
    "mean_128 = K.mean(fake_1, axis=[1,2])\n",
    "covar_128 = compute_covar(fake_1, mean_128, sz=(imageSize//2, int(imageSize*0.75)//2))\n",
    "mean_256 = K.mean(fake_2, axis=[1,2])\n",
    "covar_256 = compute_covar(fake_2, mean_256, sz=(imageSize, int(imageSize*0.75)))\n",
    "lambda1 = 1\n",
    "lambda2 = 5\n",
    "loss_C_64_128 = lambda1*K.mean(K.square(mean_128-mean_64)) + lambda2*K.mean(K.square(covar_128-covar_64))\n",
    "loss_C_128_256 = lambda1*K.mean(K.square(mean_256-mean_128)) + lambda2*K.mean(K.square(covar_256-covar_128))\n",
    "loss_C = loss_C_64_128 + loss_C_128_256 \n",
    "\n",
    "loss_G = (loss_G0 + loss_G1 + loss_G2) + 1*(1*loss_cyc + 1*gamma_i*loss_id) + 1*loss_C\n",
    "loss_D0 = loss_D0*2\n",
    "loss_D1 = loss_D1*2\n",
    "loss_D2 = loss_D2*2\n",
    "\n",
    "weightsD0 = netD0.trainable_weights\n",
    "weightsD1 = netD1.trainable_weights\n",
    "weightsD2 = netD2.trainable_weights\n",
    "weightsG = netGA.trainable_weights\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(weightsD0,[],loss_D0)\n",
    "netD0_train = K.function([real],[loss_D0/2], training_updates)\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(weightsD1,[],loss_D1)\n",
    "netD1_train = K.function([real],[loss_D1/2], training_updates)\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(weightsD2,[],loss_D2)\n",
    "netD2_train = K.function([real],[loss_D2/2], training_updates)\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(weightsG,[], loss_G)\n",
    "netG_train = K.function([real], [loss_G, loss_cyc, loss_C], training_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Image\n",
    "\n",
    "Filenames for training data:\n",
    "\n",
    "    \"./imgs/1/fileID_1.jpg\" for human images. \n",
    "    \"./imgs/5/fileID_5.jpg\" for article images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRGB = True\n",
    "apply_da = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "\n",
    "def load_data(file_pattern):\n",
    "    return glob.glob(file_pattern)\n",
    "\n",
    "def crop_img(img, large_size, small_size):\n",
    "    # only apply DA on human images\n",
    "    img_width = small_size[0]\n",
    "    img_height = small_size[1]\n",
    "    diff_size = (large_size[0]-small_size[0], large_size[1]-small_size[1])\n",
    "    \n",
    "    x_range = [i for i in range(diff_size[0])]\n",
    "    y_range = [j for j in range(diff_size[1])]\n",
    "    x0 = np.random.choice(x_range)\n",
    "    y0 = np.random.choice(y_range)\n",
    "    \n",
    "    img = np.array(img)\n",
    "    \n",
    "    img = img[y0: y0+img_height, x0: x0+img_width, :]\n",
    "    \n",
    "    return img\n",
    "\n",
    "def read_image(fn, fixed_fn_y_j=None):\n",
    "    input_size = (int(imageSize*0.75)+30, imageSize+40)\n",
    "    cropped_size = (int(imageSize*0.75), imageSize)\n",
    "    \n",
    "    if isRGB:\n",
    "    # Load human picture\n",
    "        im = Image.open(fn).convert('RGB')\n",
    "        if apply_da is True:\n",
    "            im = im.resize(input_size, Image.BILINEAR )   \n",
    "        else:\n",
    "            im = im.resize(cropped_size, Image.BILINEAR )   \n",
    "    else:\n",
    "        im = cv2.imread(fn)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        if apply_da is True:\n",
    "            im = cv2.resize(im, input_size, interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
    "    if apply_da is True:\n",
    "        im = crop_img(im, input_size, cropped_size)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_x_i = arr\n",
    "    if channel_first:        \n",
    "        img_x_i = np.moveaxis(img_x_i, 2, 0)\n",
    "        \n",
    "    # Load article picture y_i\n",
    "    fn_y_i = fn[:-5] + \"5.jpg\"\n",
    "    fn_y_i = fn_y_i[:fn_y_i.rfind(\"/\")-1] + \"5/\" + fn_y_i.split(\"/\")[-1] \n",
    "    if isRGB:\n",
    "        im = Image.open(fn_y_i).convert('RGB')\n",
    "        im = im.resize(cropped_size, Image.BILINEAR )    \n",
    "    else:\n",
    "        im = cv2.imread(fn_y_i)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_y_i = arr\n",
    "    if channel_first:        \n",
    "        img_y_i = np.moveaxis(img_y_i, 2, 0)\n",
    "    \n",
    "    # Load article picture y_j randomly\n",
    "    if fixed_fn_y_j is None:\n",
    "        fn_y_j = np.random.choice(filenames_5)\n",
    "    else:\n",
    "        fn_y_j = fixed_fn_y_j\n",
    "    while (fn_y_j == fn_y_i):\n",
    "        fn_y_j = np.random.choice(filenames_5)\n",
    "    if isRGB:\n",
    "        im = Image.open(fn_y_j).convert('RGB')\n",
    "        im = im.resize(cropped_size, Image.BILINEAR )\n",
    "    else:\n",
    "        im = cv2.imread(fn_y_j)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
    "    arr = np.array(im)/255*2-1\n",
    "    img_y_j = arr    \n",
    "    if randint(0,1): \n",
    "        img_y_j=img_y_j[:,::-1]\n",
    "    if channel_first:        \n",
    "        img_y_j = np.moveaxis(img_y_j, 2, 0)        \n",
    "    \n",
    "    if randint(0,1): # prevent disalign of the graphic on t-shirts and human when fplipping\n",
    "        img_x_i=img_x_i[:,::-1]\n",
    "        img_y_i=img_y_i[:,::-1]\n",
    "    \n",
    "    img = np.concatenate([img_x_i, img_y_i, img_y_j], axis=-1)    \n",
    "    assert img.shape[-1] == 9\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = \"imgs\"\n",
    "train_A = load_data('./{}/1/*.jpg'.format(data))\n",
    "\n",
    "filenames_1 = load_data('./{}/1/*.jpg'.format(data))\n",
    "filenames_5 = load_data('./{}/5/*.jpg'.format(data))\n",
    "\n",
    "assert len(train_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatch(data, batchsize):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None\n",
    "    shuffle(data)\n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1      \n",
    "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB(dataA, batchsize):\n",
    "    batchA=minibatch(dataA, batchsize)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        tmpsize = yield ep1, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatch_demo(data, batchsize, fn_y_i=None):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None\n",
    "    shuffle(data)\n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1    \n",
    "        rtn = [read_image(data[j], fn_y_i) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB_demo(dataA, batchsize, fn_y_i=None):\n",
    "    batchA=minibatch_demo(dataA, batchsize, fn_y_i=fn_y_i)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        tmpsize = yield ep1, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, size=(256,192), rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    if channel_first:\n",
    "        int_X = np.moveaxis(int_X.reshape(-1,3,128,96), 1, 3)\n",
    "    else:\n",
    "        if X.shape[-1] == 9:\n",
    "            img_x_i = int_X[:,:,:,:3]\n",
    "            img_y_i = int_X[:,:,:,3:6]\n",
    "            img_y_j = int_X[:,:,:,6:9]\n",
    "            int_X = np.concatenate([img_x_i, img_y_i, img_y_j], axis=1)\n",
    "        else:\n",
    "            int_X = int_X.reshape(-1, size[0], size[1], 3)\n",
    "    int_X = int_X.reshape(rows, -1, size[0], size[1], 3).swapaxes(1,2).reshape(rows*size[0],-1, 3)\n",
    "    if not isRGB:\n",
    "        int_X = cv2.cvtColor(int_X, cv2.COLOR_LAB2RGB)\n",
    "    display(Image.fromarray(int_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showG(A):\n",
    "    def G(fn_generate, X):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycle_generate, A)\n",
    "    arr = np.concatenate([A[:,:,:,:3], A[:,:,:,3:6], A[:,:,:,6:9], rA[0], rA[1]])\n",
    "    showX(arr, (imageSize, int(imageSize*0.75)), 5)  \n",
    "    rA1 = G(cycle1_generate, A)\n",
    "    arr1 = np.concatenate([rA1[0], rA1[1]])\n",
    "    showX(arr1, (imageSize//2, int(imageSize*0.75)//2), 2)      \n",
    "    rA0 = G(cycle0_generate, A)\n",
    "    arr0 = np.concatenate([rA0[0], rA0[1]])\n",
    "    showX(arr0, (imageSize//4, int(imageSize*0.75)//4), 2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "niter = 150\n",
    "gen_iterations = 0\n",
    "epoch = 0\n",
    "errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0\n",
    "\n",
    "display_iters = 50\n",
    "train_batch = minibatchAB(train_A, batchSize)\n",
    "\n",
    "#while epoch < niter: \n",
    "while gen_iterations < 8008:\n",
    "    epoch, A = next(train_batch)   \n",
    "    errDA0  = netD0_train([A])\n",
    "    errDA1  = netD1_train([A])\n",
    "    errDA2  = netD2_train([A])\n",
    "    errDA_sum += errDA2[0]\n",
    "\n",
    "    errGA, errCyc, errC = netG_train([A])\n",
    "    errGA_sum += errGA\n",
    "    errCyc_sum += errCyc\n",
    "    errC_sum += errC\n",
    "    gen_iterations+=1\n",
    "    if gen_iterations%display_iters==0:\n",
    "        if gen_iterations%(10*display_iters)==0: # clear_output every 500 iters\n",
    "            clear_output()\n",
    "        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_cyc: %f'\n",
    "        % (epoch, niter, gen_iterations, errDA_sum/display_iters,\n",
    "           errGA_sum/display_iters, errCyc_sum/display_iters), time.time()-t0)        \n",
    "        _, A = train_batch.send(4)\n",
    "        showG(A)        \n",
    "        errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Show results on fixed target article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_fn = len(filenames_5)\n",
    "idx = np.random.randint(len_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = filenames_5[idx]\n",
    "\n",
    "demo_batch = minibatchAB_demo(train_A, batchSize, fn)\n",
    "epoch, A = next(demo_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, A = demo_batch.send(8)\n",
    "showG(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
